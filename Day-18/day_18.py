# -*- coding: utf-8 -*-
"""Day-18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11g3RGmLgV-Xiq9POVFfqKYvWhmGWKrKV
"""

import seaborn as sns
import pandas as pd

df = sns.load_dataset('taxis')

df=df.dropna()
df=df.reset_index(drop=True)

df['pickup']

df['pickup'].dt.day

df['pickup'].dt.quarter

df['pickup'].dt.date

df['pickup'].dt.day

df['pickup'].dt.day_name()

df['pickup'].dt.time

df['pickup'].dt.year

df['pickup'].dt.weekday

df['pickup'].dt.hour

df['pickup'].dt.minute

df['pickup'].dt.month

df['pickup'].dt.month_name()

df['pickup'].dt.second

df['pickup_year']=df['pickup'].dt.year

df['pickup_dayname']=df['pickup'].dt.day_name

df['pickup_day']=df['pickup'].dt.day

df['pickup_month']=df['pickup'].dt.month

df['pickup_monthname']=df['pickup'].dt.month_name

df['pickup_second']=df['pickup'].dt.second

df.head()

df.pickup_month.value_counts()

df['dropoff_monthname']=df['dropoff'].dt.month_name()
df['dropoff_month']=df['dropoff'].dt.month
df['dropoff_year']=df['dropoff'].dt.year
df['dropoff_dayname']=df['dropoff'].dt.day_name()
df['dropoff_day']=df['dropoff'].dt.day
df['dropoff_hour']=df['dropoff'].dt.hour
df['dropoff_minute']=df['dropoff'].dt.minute
df['dropoff_second']=df['dropoff'].dt.second
df['dropoff_quarter']=df['dropoff'].dt.quarter

df.shape

df.head()

df.columns

from scipy import stats

r, p_val = stats. spearmanr(df['tip' ],df['dropoff_dayname' ])
print("correlation:", r)
print("P-value:", p_val)
alpha=0.05
if p_val < alpha:
  print("Reject null hypothesis: There is no relationship")
else:
  print("Fail to reject null hypothesis: There is significant relationship")

drop_list = [
    'pickup',
    'dropoff',
    'pickup_month',
    'pickup_day',
    'pickup_year',
    'pickup_borough',
    'dropoff_borough',
    'dropoff_day',
    'dropoff_month',
    'dropoff_year',
    'dropoff_minute',
    'dropoff_second',
    'dropoff_quarter'
]

df.drop(columns=drop_list, inplace=True, errors='ignore')

from sklearn.preprocessing import LabelEncoder

lb = LabelEncoder()

cat = [
    'color',
    'payment',
    'pickup_zone',
    'dropoff_zone',
    'pickup_borough',
    'dropoff_borough',
    'pickup_dayname',
    'dropoff_dayname'
]

for col in cat:
    if col in df.columns:
        df[col] = lb.fit_transform(df[col])

df.head()

x = df.drop('tip', axis=1)
y = df['tip']

print(x.shape)
print(y.shape)

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.25, random_state=42
)

print('X train shape:', x_train.shape)
print('Y train shape:', y_train.shape)
print('X test shape :', x_test.shape)
print('Y test shape :', y_test.shape)

df = pd.get_dummies(df, drop_first=True)

x_train.dtypes

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(x_train, y_train)

model. coef_

model.intercept_

"""**Training Score**"""

y_train_pred=model.predict(x_train)
train_score=model.score(x_train,y_train)
print("Model Training Score : ", train_score)

y_test_pred=model.predict(x_test)
test_score=model.score(x_test,y_test)
print("Model Training Score : ",test_score)

from sklearn.metrics import root_mean_squared_error, mean_squared_error, mean_absolute_error, r2_score

root_mean_squared_error(y_train,y_train_pred)

mean_squared_error(y_train,y_train_pred)

mean_absolute_error(y_train,y_train_pred)

import pandas as pd

# Path for uploaded file in Colab
path = '/content/Position_Salaries.csv'

# Importing the dataset
dataset = pd.read_csv(path)
# Independent variable (Position Level)
X = dataset.iloc[ :, 1 :- 1].values

# Dependent variable (Salary)
y = dataset. iloc[:, -1]. values

# Display dataset preview
print("Dataset Preview:")
print(dataset.head())

# Verify shapes
print("X shape:", X.shape)
print("y shape:", y.shape)

from sklearn.model_selection import train_test_split

# Splitting the dataset into Training and Test set
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42
)

# Check shapes
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)

# Training the Linear Regression model on the whole dataset
from sklearn.linear_model import LinearRegression
lin_reg = LinearRegression()
lin_reg.fit(X, y)

# Training the Polynomial Regression model on the whole dataset
from sklearn.preprocessing import PolynomialFeatures
poly_reg = PolynomialFeatures(degree = 4)
X_poly = poly_reg.fit_transform(X)
lin_reg_2 = LinearRegression()
lin_reg_2.fit(X_poly, y)

print("âœ… Models Trained Successfully!")

import matplotlib.pyplot as plt

# Visualising the Linear Regression results
plt.scatter(X, y, color = 'red')
plt.plot(X, lin_reg.predict(X), color = 'blue')
plt.title('Truth or Bluff (Linear Regression)')
plt.xlabel('Position Level')
plt.ylabel('Salary')
plt.show()

# Visualising the Polynomial Regression results
plt.scatter(X, y, color = 'red' )
plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = 'blue')
plt.title('Truth or Bluff (Polynomial Regression)')
plt.xlabel('Position level')
plt.ylabel('Salary')
plt.show()

# Predicting a new result with Linear Regression
linear_prediction = lin_reg.predict([[6.5]])
print("Linear Regression Prediction for Level 6.5:", linear_prediction)

# Predicting a new result with Polynomial Regression
poly_prediction = lin_reg_2.predict(poly_reg.fit_transform([[6.5]]))
print("Polynomial Regression Prediction for Level 6.5:", poly_prediction)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Predictions on entire dataset (or test set if you have one)
y_pred = lin_reg.predict(X)

# Metrics
mse = mean_squared_error(y, y_pred)
mae = mean_absolute_error(y, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y, y_pred)

# Print metrics
print("Mean Squared Error (MSE):", mse)
print("Mean Absolute Error (MAE):", mae)
print("Root Mean Squared Error (RMSE):", rmse)
print("R2 Score:", r2)

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Predict on full dataset using polynomial features
y_poly_pred = lin_reg_2.predict(poly_reg.transform(X))

# Metrics
mse_poly = mean_squared_error(y, y_poly_pred)
mae_poly = mean_absolute_error(y, y_poly_pred)
rmse_poly = np.sqrt(mse_poly)
r2_poly = r2_score(y, y_poly_pred)

# Print metrics
print("Polynomial Regression Metrics")
print("Mean Squared Error (MSE):", mse_poly)
print("Mean Absolute Error (MAE):", mae_poly)
print("Root Mean Squared Error (RMSE):", rmse_poly)
print("R2 Score:", r2_poly)